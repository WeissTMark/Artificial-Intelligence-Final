{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00801964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neural_network as mlp\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    #Load MNIST data from `path`\n",
    "\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte' % kind)\n",
    "\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte' % kind)\n",
    "\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "\n",
    "        magic, n = struct.unpack('>II', lbpath.read(8))\n",
    "\n",
    "        labels = np.fromfile(lbpath, dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", imgpath.read(16))\n",
    "\n",
    "        images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "imgs, labels = load_mnist(\"./\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4d555ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.50720075\n",
      "Iteration 2, loss = 0.27645149\n",
      "Iteration 3, loss = 0.24295514\n",
      "Iteration 4, loss = 0.22249844\n",
      "Iteration 5, loss = 0.21140488\n",
      "Iteration 6, loss = 0.19740062\n",
      "Iteration 7, loss = 0.19080450\n",
      "Iteration 8, loss = 0.19048063\n",
      "Iteration 9, loss = 0.18324910\n",
      "Iteration 10, loss = 0.16899873\n",
      "Iteration 11, loss = 0.16909016\n",
      "Iteration 12, loss = 0.16742641\n",
      "Iteration 13, loss = 0.17140866\n",
      "Iteration 14, loss = 0.16827328\n",
      "Iteration 15, loss = 0.16271103\n",
      "Iteration 16, loss = 0.15731637\n",
      "Iteration 17, loss = 0.15058802\n",
      "Iteration 18, loss = 0.14772120\n",
      "Iteration 19, loss = 0.14989534\n",
      "Iteration 20, loss = 0.14467371\n",
      "Iteration 21, loss = 0.14093790\n",
      "Iteration 22, loss = 0.14552106\n",
      "Iteration 23, loss = 0.14951017\n",
      "Iteration 24, loss = 0.14770880\n",
      "Iteration 25, loss = 0.13724909\n",
      "Iteration 26, loss = 0.13653792\n",
      "Iteration 27, loss = 0.13285923\n",
      "Iteration 28, loss = 0.14840520\n",
      "Iteration 29, loss = 0.13924609\n",
      "Iteration 30, loss = 0.13335305\n",
      "Iteration 31, loss = 0.13011326\n",
      "Iteration 32, loss = 0.13240739\n",
      "Iteration 33, loss = 0.13434457\n",
      "Iteration 34, loss = 0.12615144\n",
      "Iteration 35, loss = 0.12109195\n",
      "Iteration 36, loss = 0.12590136\n",
      "Iteration 37, loss = 0.12710343\n",
      "Iteration 38, loss = 0.13129720\n",
      "Iteration 39, loss = 0.12648928\n",
      "Iteration 40, loss = 0.12263850\n",
      "Iteration 41, loss = 0.12307929\n",
      "Iteration 42, loss = 0.11951406\n",
      "Iteration 43, loss = 0.11695843\n",
      "Iteration 44, loss = 0.11826233\n",
      "Iteration 45, loss = 0.11915616\n",
      "Iteration 46, loss = 0.11490784\n",
      "Iteration 47, loss = 0.11378980\n",
      "Iteration 48, loss = 0.11583589\n",
      "Iteration 49, loss = 0.11231422\n",
      "Iteration 50, loss = 0.10919674\n",
      "Iteration 51, loss = 0.11061166\n",
      "Iteration 52, loss = 0.11095858\n",
      "Iteration 53, loss = 0.11133438\n",
      "Iteration 54, loss = 0.11673792\n",
      "Iteration 55, loss = 0.11208547\n",
      "Iteration 56, loss = 0.11142402\n",
      "Iteration 57, loss = 0.11591230\n",
      "Iteration 58, loss = 0.11057073\n",
      "Iteration 59, loss = 0.10700994\n",
      "Iteration 60, loss = 0.10298091\n",
      "Iteration 61, loss = 0.10312152\n",
      "Iteration 62, loss = 0.09977905\n",
      "Iteration 63, loss = 0.10344654\n",
      "Iteration 64, loss = 0.10254966\n",
      "Iteration 65, loss = 0.09941168\n",
      "Iteration 66, loss = 0.09615881\n",
      "Iteration 67, loss = 0.10104070\n",
      "Iteration 68, loss = 0.10254641\n",
      "Iteration 69, loss = 0.09826338\n",
      "Iteration 70, loss = 0.09692042\n",
      "Iteration 71, loss = 0.09757292\n",
      "Iteration 72, loss = 0.09899642\n",
      "Iteration 73, loss = 0.10068220\n",
      "Iteration 74, loss = 0.10151533\n",
      "Iteration 75, loss = 0.10321427\n",
      "Iteration 76, loss = 0.09754592\n",
      "Iteration 77, loss = 0.09586466\n",
      "Iteration 78, loss = 0.10109484\n",
      "Iteration 79, loss = 0.09992690\n",
      "Iteration 80, loss = 0.10373481\n",
      "Iteration 81, loss = 0.09689646\n",
      "Iteration 82, loss = 0.09528879\n",
      "Iteration 83, loss = 0.09395598\n",
      "Iteration 84, loss = 0.09037675\n",
      "Iteration 85, loss = 0.09089438\n",
      "Iteration 86, loss = 0.09206454\n",
      "Iteration 87, loss = 0.09759748\n",
      "Iteration 88, loss = 0.09677805\n",
      "Iteration 89, loss = 0.09203603\n",
      "Iteration 90, loss = 0.08918042\n",
      "Iteration 91, loss = 0.09045448\n",
      "Iteration 92, loss = 0.09114370\n",
      "Iteration 93, loss = 0.08616319\n",
      "Iteration 94, loss = 0.09214412\n",
      "Iteration 95, loss = 0.09567517\n",
      "Iteration 96, loss = 0.09390835\n",
      "Iteration 97, loss = 0.08961333\n",
      "Iteration 98, loss = 0.08908074\n",
      "Iteration 99, loss = 0.08881636\n",
      "Iteration 100, loss = 0.08652694\n",
      "Iteration 101, loss = 0.08110373\n",
      "Iteration 102, loss = 0.08397776\n",
      "Iteration 103, loss = 0.08291544\n",
      "Iteration 104, loss = 0.08317644\n",
      "Iteration 105, loss = 0.08572352\n",
      "Iteration 106, loss = 0.08550957\n",
      "Iteration 107, loss = 0.08312471\n",
      "Iteration 108, loss = 0.08565726\n",
      "Iteration 109, loss = 0.08958053\n",
      "Iteration 110, loss = 0.10053667\n",
      "Iteration 111, loss = 0.10912895\n",
      "Iteration 112, loss = 0.09667685\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Training time: 400.8998076915741\n",
      "0.9632\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "perc = mlp.MLPClassifier(activation='logistic', alpha= 0.0001, hidden_layer_sizes=200, \n",
    "                         learning_rate= 'adaptive', max_iter= 200, verbose=True)\n",
    "\n",
    "perc.fit(imgs, labels)\n",
    "t1 = time.time()\n",
    "print(\"Training time: \" + str(abs(t0 - t1)))\n",
    "\n",
    "\n",
    "\n",
    "testImgs, testLabels = load_mnist(\"./\", \"t10k\")\n",
    "\n",
    "print(perc.score(testImgs, testLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7f9a8e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted = perc.predict(testImgs)\n",
    "\n",
    "errors = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "errImg = []\n",
    "errLbl = []\n",
    "errCrc = []\n",
    "i = 0\n",
    "for image, prediction, actual in zip(testImgs, predicted, testLabels):\n",
    "    if (prediction != actual):\n",
    "        errors[actual] += 1\n",
    "        errImg.append(image)\n",
    "        errLbl.append(prediction)\n",
    "        errCrc.append(actual)\n",
    "        \n",
    "_, axes = plt.subplots(nrows=1, ncols=10, figsize=(15, 5))\n",
    "for ax, image, prediction, actual in zip(axes, errImg, errLbl, errCrc):\n",
    "    ax.set_axis_off()\n",
    "    image = image.reshape(28, 28)\n",
    "    ax.imshow(image, cmap='gray', interpolation=\"nearest\")\n",
    "    ax.set_title(f\"P: {prediction} A: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d73af1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.79881104\n",
      "Iteration 2, loss = 1.30574311\n",
      "Iteration 3, loss = 1.05460548\n",
      "Iteration 4, loss = 0.89946749\n",
      "Iteration 5, loss = 0.77750381\n",
      "Iteration 6, loss = 0.69273501\n",
      "Iteration 7, loss = 0.64176964\n",
      "Iteration 8, loss = 0.59890768\n",
      "Iteration 9, loss = 0.57719742\n",
      "Iteration 10, loss = 0.54993996\n",
      "Iteration 11, loss = 0.54863130\n",
      "Iteration 12, loss = 0.52257918\n",
      "Iteration 13, loss = 0.51625675\n",
      "Iteration 14, loss = 0.50643306\n",
      "Iteration 15, loss = 0.49558643\n",
      "Iteration 16, loss = 0.49698624\n",
      "Iteration 17, loss = 0.48844613\n",
      "Iteration 18, loss = 0.48737020\n",
      "Iteration 19, loss = 0.47727121\n",
      "Iteration 20, loss = 0.47779745\n",
      "Iteration 21, loss = 0.46453772\n",
      "Iteration 22, loss = 0.46240698\n",
      "Iteration 23, loss = 0.46134431\n",
      "Iteration 24, loss = 0.46251530\n",
      "Iteration 25, loss = 0.44717806\n",
      "Iteration 26, loss = 0.44789823\n",
      "Iteration 27, loss = 0.45112791\n",
      "Iteration 28, loss = 0.44675441\n",
      "Iteration 29, loss = 0.44197399\n",
      "Iteration 30, loss = 0.44350091\n",
      "Iteration 31, loss = 0.44387857\n",
      "Iteration 32, loss = 0.43357662\n",
      "Iteration 33, loss = 0.43241914\n",
      "Iteration 34, loss = 0.43064088\n",
      "Iteration 35, loss = 0.43153519\n",
      "Iteration 36, loss = 0.43524010\n",
      "Iteration 37, loss = 0.43497330\n",
      "Iteration 38, loss = 0.43219129\n",
      "Iteration 39, loss = 0.42699897\n",
      "Iteration 40, loss = 0.43409854\n",
      "Iteration 41, loss = 0.42725992\n",
      "Iteration 42, loss = 0.42264680\n",
      "Iteration 43, loss = 0.41638907\n",
      "Iteration 44, loss = 0.42947839\n",
      "Iteration 45, loss = 0.41864839\n",
      "Iteration 46, loss = 0.42463336\n",
      "Iteration 47, loss = 0.43424370\n",
      "Iteration 48, loss = 0.41050413\n",
      "Iteration 49, loss = 0.41392722\n",
      "Iteration 50, loss = 0.41456469\n",
      "Iteration 51, loss = 0.40725903\n",
      "Iteration 52, loss = 0.39631536\n",
      "Iteration 53, loss = 0.38912528\n",
      "Iteration 54, loss = 0.39335362\n",
      "Iteration 55, loss = 0.40054198\n",
      "Iteration 56, loss = 0.39251499\n",
      "Iteration 57, loss = 0.39604818\n",
      "Iteration 58, loss = 0.38686189\n",
      "Iteration 59, loss = 0.38589257\n",
      "Iteration 60, loss = 0.37617585\n",
      "Iteration 61, loss = 0.38328625\n",
      "Iteration 62, loss = 0.37900448\n",
      "Iteration 63, loss = 0.37610673\n",
      "Iteration 64, loss = 0.38532876\n",
      "Iteration 65, loss = 0.38049382\n",
      "Iteration 66, loss = 0.37671514\n",
      "Iteration 67, loss = 0.36988940\n",
      "Iteration 68, loss = 0.36751281\n",
      "Iteration 69, loss = 0.35700873\n",
      "Iteration 70, loss = 0.36567901\n",
      "Iteration 71, loss = 0.36057660\n",
      "Iteration 72, loss = 0.36064865\n",
      "Iteration 73, loss = 0.36130311\n",
      "Iteration 74, loss = 0.36131133\n",
      "Iteration 75, loss = 0.35856668\n",
      "Iteration 76, loss = 0.35629351\n",
      "Iteration 77, loss = 0.36598277\n",
      "Iteration 78, loss = 0.36040141\n",
      "Iteration 79, loss = 0.36367118\n",
      "Iteration 80, loss = 0.35698435\n",
      "Iteration 81, loss = 0.36103630\n",
      "Iteration 82, loss = 0.36089242\n",
      "Iteration 83, loss = 0.35296838\n",
      "Iteration 84, loss = 0.34953305\n",
      "Iteration 85, loss = 0.34643081\n",
      "Iteration 86, loss = 0.35116237\n",
      "Iteration 87, loss = 0.36126667\n",
      "Iteration 88, loss = 0.35897628\n",
      "Iteration 89, loss = 0.36181468\n",
      "Iteration 90, loss = 0.36364251\n",
      "Iteration 91, loss = 0.34799349\n",
      "Iteration 92, loss = 0.34717632\n",
      "Iteration 93, loss = 0.35792493\n",
      "Iteration 94, loss = 0.34569749\n",
      "Iteration 95, loss = 0.34954209\n",
      "Iteration 96, loss = 0.34775968\n",
      "Iteration 97, loss = 0.34881008\n",
      "Iteration 98, loss = 0.34806670\n",
      "Iteration 99, loss = 0.34978889\n",
      "Iteration 100, loss = 0.33937627\n",
      "Iteration 101, loss = 0.34025051\n",
      "Iteration 102, loss = 0.34744871\n",
      "Iteration 103, loss = 0.35233386\n",
      "Iteration 104, loss = 0.34664766\n",
      "Iteration 105, loss = 0.34333944\n",
      "Iteration 106, loss = 0.34368521\n",
      "Iteration 107, loss = 0.33876650\n",
      "Iteration 108, loss = 0.34367200\n",
      "Iteration 109, loss = 0.33508876\n",
      "Iteration 110, loss = 0.33936599\n",
      "Iteration 111, loss = 0.33576214\n",
      "Iteration 112, loss = 0.34096028\n",
      "Iteration 113, loss = 0.34096208\n",
      "Iteration 114, loss = 0.33081269\n",
      "Iteration 115, loss = 0.33831101\n",
      "Iteration 116, loss = 0.33970772\n",
      "Iteration 117, loss = 0.34248160\n",
      "Iteration 118, loss = 0.33871318\n",
      "Iteration 119, loss = 0.34263609\n",
      "Iteration 120, loss = 0.34429912\n",
      "Iteration 121, loss = 0.34641376\n",
      "Iteration 122, loss = 0.33669055\n",
      "Iteration 123, loss = 0.33986517\n",
      "Iteration 124, loss = 0.34797061\n",
      "Iteration 125, loss = 0.34597673\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Best parameters found:\n",
      " {'activation': 'logistic', 'alpha': 0.0001, 'batch_size': 200, 'hidden_layer_sizes': 10, 'learning_rate': 'adaptive', 'max_iter': 150, 'verbose': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mlpCV = mlp.MLPClassifier()\n",
    "parameter_space = {\n",
    "    'verbose': [True],\n",
    "    'hidden_layer_sizes': [10],\n",
    "    'activation': ['logistic'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'max_iter': [50, 100, 150],\n",
    "    'batch_size': [100, 200, 300]\n",
    "}\n",
    "\n",
    "\n",
    "best = GridSearchCV(mlpCV, parameter_space, n_jobs=-1, cv=5)\n",
    "best.fit(imgs, labels)\n",
    "\n",
    "print('Best parameters found:\\n', best.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e190201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bf9392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
